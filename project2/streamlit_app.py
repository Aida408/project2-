import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import numpy as np

# ===============================
# 1Ô∏è‚É£ –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ (–¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–Ω–æ–π)
# ===============================
class BetterNet(nn.Module):
    def __init__(self):
        super(BetterNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.5)
        self.fc1 = nn.Linear(256 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.pool(F.relu(self.bn3(self.conv3(x))))
        x = torch.flatten(x, 1)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.fc2(x)
        return x

# ===============================
# 2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# ===============================
@st.cache_resource
def load_model():
    model = BetterNet()
    model.load_state_dict(torch.load("improved_cifar10.pth", map_location=torch.device("cpu")))
    model.eval()
    return model

model = load_model()

# ===============================
# 3Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
# ===============================
st.title("üß† –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π CIFAR-10")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (32x32 –∏–ª–∏ –±–æ–ª—å—à–µ), –∏ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç, –∫ –∫–∞–∫–æ–º—É –∫–ª–∞—Å—Å—É –æ–Ω–æ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è.")

classes = ['plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck']

uploaded_file = st.file_uploader("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", type=["jpg", "jpeg", "png"])

# ===============================
# 4Ô∏è‚É£ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
# ===============================
if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

    transform = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    img_t = transform(image)
    img_t = img_t.unsqueeze(0)  # –¥–æ–±–∞–≤–ª—è–µ–º batch dimension

    with torch.no_grad():
        outputs = model(img_t)
        _, predicted = torch.max(outputs, 1)
        class_name = classes[predicted.item()]

    st.markdown(f"### üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: **{class_name.upper()}**")

